# GenAI-Testing Primes

In this test, we want to benchmark different generative AI's to see how they perform and how they evolved over time.

We have tested

1. Myself - How I solved the problems (January 2024)
2. OpenAI ChatGPT 4
3. Google Gemini Advanced 1.5
4. OpenAI ChatGPT 5.1 thinking
5. Google Gemini 3 Pro thinking
6. Claude Opus 4.5 thinking

The tests are run with a HP z420 with Xeon E5-2660 v2 CPU.

## Problem 1

To solve this problem, you are not allowed to use any external libraries. Also, you have to make this algorithm as fast as possible. The code has to be written in Python.

There is a sequence of numbers generated by the formula

    X(0) = 1
    X(n+1) = mod(2147483647*X(n)+137438953471, 1400) + 1

Your task is to take all prime numbers from the sequence X(1), ..., X(1E8) and sum them together. Note, we do not include X(0) in the series.

## Problem 2

There is a sequence of cyclic numbers generated by the code

    import random
    random.seed(1)

    def generator():
        return random.randint(1, 100000000)

Your task is to take all prime numbers from the sequence X(1), ..., X(1E8) and sum them together. The first generated number of generator() is X(1). You have to makes this solver as fast as possible. You are not allowed to use any libraries.

## Problem 3

Find the largest prime where all digits are different. Naturally, this prime is smaller than the number 9876543210. You are allowed to use Python libraries to solve this problem.

## Results Problem 1 - Round 1

This is the first round of test. Where I, ChatGPT, Gemini and Claude have not been informed that the generated numbers follow a cyclic pattern.

The correct answer is **19268573182**

Mikael: Built a disctionary of primes. Brute Force algorithm.
ChatGPT 4: Discovered the problem is cyclic, but did not exploit it in its algorithm.
Gemini 1.5: Built an boolean array of prime numbers. Brute force algorithm.
ChatGPT 5.1: Exploited cyclic pattern.
Gemini 3: Exploited cyclic pattern.
Opus 4.5: Exploited cyclic pattern.

Comment from ChatGPT 4

    "A key insight to optimize further is recognizing patterns or cycles within the sequence generated by the formula. Due to the modulo operation, the sequence might enter a cycle where the same numbers start repeating after a certain point. This would drastically reduce the number of unique values we need to check for primality.

    Let's refine our strategy with a focus on identifying a cycle within the sequence. If a cycle is detected, we can calculate the sum of primes within one cycle and then use this information to compute the total sum for all cycles up to X(100,000,000)X(100,000,000) without iterating through every single value.

    1) Detect a cycle: Modify the sequence generation to detect a cycle.
    2) Compute sum within the cycle: Once a cycle is detected, compute the sum of primes within that cycle.
    3) Extrapolate to the total sum: Calculate how many complete cycles fit into 100,000,000 iterations and sum accordingly."


### Summary Table (5 runs each)

| Rank | Algorithm       | Avg Time (s) | Min (s)  | Max (s)  | Approach |
|------|-----------------|--------------|----------|----------|----------|
| 1    | Claude Opus 4.5 | 0.0234       | 0.0232   | 0.0237   | Cycle detection |
| 2    | Gemini 3 Pro    | 0.0236       | 0.0234   | 0.0240   | Cycle detection |
| 3    | ChatGPT 5.1     | 0.0245       | 0.0240   | 0.0256   | Cycle detection |
| 4    | ChatGPT 4       | 32.0699      | 31.7888  | 32.2294  | Brute force |
| 5    | Mikael          | 53.2247      | 52.2318  | 54.3069  | Brute force |
| 6    | Gemini 1.5      | 55.6838      | 55.3922  | 56.1119  | Brute force |

All algorithms produced the correct answer: **19268573182**

### Performance Diagram

```
Claude Opus 4.5 │ █ 0.0234s
Gemini 3 Pro    │ █ 0.0236s
ChatGPT 5.1     │ █ 0.0245s
ChatGPT 4       │ ██████████████████████████████████████████████ 32.07s
Mikael          │ █████████████████████████████████████████████████ 53.22s
Gemini 1.5      │ ██████████████████████████████████████████████████ 55.68s
```

### Key Findings

- **Fastest**: Claude Opus 4.5 (23.36 ms)
- **Slowest**: Gemini 1.5 (55.68 s)
- **Speed difference**: ~2383x between fastest and slowest

### Categories

**FAST (<100ms)** - Used cycle detection optimization:
- Claude Opus 4.5: 23.36ms
- Gemini 3 Pro: 23.61ms
- ChatGPT 5.1: 24.52ms

**SLOW (>10s)** - Brute force iteration:
- ChatGPT 4: 32.07s
- Mikael: 53.22s
- Gemini 1.5: 55.68s

### Analysis

The newer "thinking" models (ChatGPT 5.1, Gemini 3 Pro, Claude Opus 4.5) all discovered that the sequence has a cyclic pattern due to the modulo operation with 1400. This allowed them to:
1. Detect the cycle length (at most 1400 unique values)
2. Calculate the sum using multiplication instead of iterating 10^8 times

The older models and human solution used brute force iteration through all 10^8 values, resulting in ~2000x slower performance.

## Results Problem 1 - Round 2

Now myself and Gemini 1.5 are informed, that there is cyclic behaviour because of the modulus operator and how the numbers are generated. ChatGPT 4 was told it must implemnt its own idea.

This time Gemini 1.5 came up with the wrong answer and it was also slower.

Wrong answer: 69799288914

    real    1m38,024s
    user    1m30,703s
    sys     0m7,262s

### Summary Table (5 runs each)

| Rank | Algorithm       | Avg Time (s) | Min (s)  | Max (s)  |
|------|-----------------|--------------|----------|----------|
| 1    | Mikael          | 0.0234       | 0.0231   | 0.0238   |
| 2    | Gemini 3 Pro    | 0.0239       | 0.0232   | 0.0244   |
| 3    | ChatGPT 5.1     | 0.0249       | 0.0241   | 0.0254   |
| 4    | Claude Opus 4.5 | 0.0255       | 0.0236   | 0.0325   |
| 5    | ChatGPT 4       | 0.0270       | 0.0239   | 0.0368   |
| -    | Gemini 1.5      | FAILED       | -        | -        |

All working algorithms produced the correct answer: **19268573182**

### Performance Diagram

```
Mikael          │ ████████████████████████████████████████████ 0.0234s
Gemini 3 Pro    │ █████████████████████████████████████████████ 0.0239s
ChatGPT 5.1     │ ███████████████████████████████████████████████ 0.0249s
Claude Opus 4.5 │ ████████████████████████████████████████████████ 0.0255s
ChatGPT 4       │ ██████████████████████████████████████████████████ 0.0270s
Gemini 1.5      │ FAILED (wrong answer: 69799288914)
```

### Key Findings

- Once informed about the cyclic pattern, **all models except Gemini 1.5** achieved similar fast performance (~23-27ms)
- **Mikael** (human solution) was now the fastest at 23.4ms after being told about the optimization
- **ChatGPT 4** successfully implemented its own cycle detection idea from Round 1
- **Gemini 1.5** failed to produce the correct answer even when informed about the cyclic pattern

## Results Problem 1 - Round 3

Even if Gemini was showed the code from me and ChatGPT 4, it was still not able to solve problem 1.

Wrong answer: 69799288864

    real    1m0,793s
    user    0m53,336s
    sys     0m7,420s

## Results Problem 2 - Round 1

Problem 2 is harder to solve, since it has no cycles. All algorithms must use the Sieve of Eratosthenes to generate primes up to 10^8 and then iterate through all 10^8 random numbers.

The correct answer is **279337398623953**

Gemini 1.5 produced random garbarge code and appeared lazy.

ChatGPT 5.1 hallucinated and claimed the problem has no solution.

### Summary Table (5 runs each)

| Rank | Algorithm       | Avg Time (s) | Min (s)  | Max (s)  | Approach |
|------|-----------------|--------------|----------|----------|----------|
| 1    | Gemini 3 Pro    | 115.67       | 115.21   | 116.01   | Sieve + iteration |
| 2    | Claude Opus 4.5 | 115.88       | 115.36   | 116.58   | Sieve + iteration |
| 3    | ChatGPT 4       | 154.80       | 153.31   | 157.36   | Sieve + iteration |
| 4    | Mikael          | 162.81       | 161.05   | 165.20   | Sieve + iteration |
| -    | ChatGPT 5.1     | FAILED       | -        | -        | - |
| -    | Gemini 1.5      | FAILED       | -        | -        | - |

All working algorithms produced the correct answer: **279337398623953**

### Performance Diagram

```
Gemini 3 Pro    │ ██████████████████████████████████████████████████ 115.67s
Claude Opus 4.5 │ ██████████████████████████████████████████████████ 115.88s
ChatGPT 4       │ █████████████████████████████████████████████████████████████████ 154.80s
Mikael          │ ██████████████████████████████████████████████████████████████████████ 162.81s
ChatGPT 5.1     │ FAILED
Gemini 1.5      │ FAILED
```

### Key Findings

- **Fastest**: Gemini 3 Pro (115.67s) and Claude Opus 4.5 (115.88s) were essentially tied
- **Slowest working**: Mikael (162.81s)
- **Speed difference**: ~1.41x between fastest and slowest working algorithm
- **Failures**: Both ChatGPT 5.1 and Gemini 1.5 failed to produce correct results

### Analysis

Without cyclic patterns to exploit, all algorithms had to:
1. Build a sieve of primes up to 10^8 (~100 million numbers)
2. Iterate through all 10^8 random numbers and sum the primes

The performance differences came from:
- **Memory optimization**: Gemini 3 Pro and Claude Opus 4.5 used `bytearray` with optimized slice assignment
- **Sieve optimization**: Claude Opus 4.5 used odd-only sieve (halving memory usage)
- **Loop optimization**: Caching `random.randint` to local variables to avoid repeated dictionary lookups

## Results Problem 2 - Round 2

Gemini 1.5 still refused to attempt to solve the problem.

ChatGPT 5.1 was told the correct answer and given a second chance. ChatGPT 5.1 then claimed it had run the code locally, had the correct answer, and was double as fast as the other generative AI's. On my computer, the ChatGPT 5.1 code timed out after 10 minutes and we do not know if its algorithm would give the correct answer. We should consider it as a FAIL.

## Results Problem 3

Correct answer: 987654103

### ChatGPT 4

Completely failed with junk code.

Wrong answer: 101

### ChatGPT 5.1

Came up with a fast and correct answer, only 5.5 seconds.

Correct answer: 987654103

### Gemini 1.5

Completely failed with junk code.

Wrong answer: 1234657

### Opus 4.5

Had some very fast algorithm, 20ms, but did not find the largest prime number. I am sure it could fix its own mistake and come up with correct answer under 1 second.

Wrong answer: 987625403

### Gemini 3

Gemini 3 found the correct answer, but was also cheating, it knew which digit to remove. I am sure it could fix its own mistake and come up with correct answer under 1 second.

Correct answer: 987654103 (cheating)

### Mikael

I found a working algorithm, but it was not fast, whooping 4.3 seconds or 2.2 seconds if I skip the 10 digit primes. Claude, ChatGPT and Gemini all knew about some tricks to skip computing the 10 sigit prime, I did not know.

Correct answer: 987654103